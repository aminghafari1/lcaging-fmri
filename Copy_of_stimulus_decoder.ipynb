{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSVSZbvBhVqUXlivgy/42m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aminghafari1/lcaging-fmri/blob/main/Copy_of_stimulus_decoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbsQAuv8rSLU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5bcdfbb-f8ce-4cd3-e66d-46f4e1242476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "## This code is for reading the subject data and trying to get the EV files responsible for the visual and auditory stimuli.\n",
        "## The outline is that the subject number is entered and the resulting output is EV files for all the contrasts tha are considered.\n",
        "## For now I'm gonna only focus on separating the effect of the grip from the V/A stimuli, then we will see what to do with the \n",
        "## different stimulus/handgrip levels and also the subject answers and the confidence ratings.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "def substring_after(s,delim):\n",
        "  return s.partition(delim)[2]\n",
        "import scipy.io as sio\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub_num=input(\"Please enter the subject number:\")\n",
        "print(\"Working on the visual and auditory data of sub %s now.\" %(sub_num))\n",
        "\n",
        "base_dir=glob.glob('/content/gdrive/Shareddrives/LC-Aging/'\\\n",
        "  'Older Adult - MRI Study/Data Collection/BAP/BAP data/')\n",
        "base_dir=base_dir[0]\n",
        "sub_folder_name=\"sub-BAP\"+sub_num\n",
        "z=os.listdir(base_dir)\n",
        "print(\"The folder we are looking for here is: %s\" %(sub_folder_name))\n",
        "while sub_num != \"quit\":\n",
        "    if sub_folder_name in z:\n",
        "        print(\"The folder %s was found in the list.\" %(sub_folder_name) )\n",
        "        break\n",
        "    else:\n",
        "        print(\"The folder %s was not found in the list.\" %(sub_folder_name) )\n",
        "        print(\"Please enter another subject code or type 'quit' to exit.\")\n",
        "    sub_num = input(\"Please enter a subject number or type 'quit' to exit: \")\n",
        "subject_folder=base_dir+sub_folder_name\n",
        "print(subject_folder)\n",
        "sessions=[2,3]\n",
        "for session_number in sessions:\n",
        "  temp=\"/ses-%s/InsideScanner\" %(session_number)\n",
        "  scans_folder=subject_folder+temp\n",
        "  scans_contents=os.listdir(scans_folder)\n",
        "  mat_files= [element for element in scans_contents if element.endswith('.mat') and \"eyetrack\" not in element and \"MVCnPRAC\" not in element]\n",
        "  temp_perf=mat_files[0]\n",
        "  if \"Voddball\" in temp_perf:\n",
        "    visual_files=mat_files\n",
        "    visual_scans_folder=scans_folder+\"/\"\n",
        "  else:\n",
        "    audio_files=mat_files\n",
        "    audio_scans_folder=scans_folder+\"/\"\n",
        "  \n",
        "## Finding the save directory\n",
        "res_directory=\"BAP\"+str(sub_num)\n",
        "print(res_directory)\n",
        "save_dir_vis='/content/gdrive/Shareddrives/LC-Aging/LC_aging_fMRI/%s/visual' %(res_directory)\n",
        "save_dir_aud='/content/gdrive/Shareddrives/LC-Aging/LC_aging_fMRI/%s/auditory' %(res_directory)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayFIpXE_sRoL",
        "outputId": "ab1a3d4c-fea2-4a30-ced9-3a5c9d85d981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter the subject number:103\n",
            "Working on the visual and auditory data of sub 103 now.\n",
            "The folder we are looking for here is: sub-BAP103\n",
            "The folder sub-BAP103 was found in the list.\n",
            "/content/gdrive/Shareddrives/LC-Aging/Older Adult - MRI Study/Data Collection/BAP/BAP data/sub-BAP103\n",
            "BAP103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"BAP\"+str(sub_num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gYMWsSoO8IRZ",
        "outputId": "07d80c6f-a8ec-4134-de48-bcb99a50ced1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'BAP103'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Because in some of the subjects the number of auditory tasks might differ from the visual ones\n",
        "## we need to exploit 2 for loops, one for each here.\n",
        "## This section is only for the visual test\n",
        "number_of_trials_per_run=30\n",
        "visual_ones=np.ones(2*number_of_trials_per_run)\n",
        "grip_ones=np.ones(number_of_trials_per_run)\n",
        "for current_file in visual_files:\n",
        "  task_file=current_file\n",
        "  file_directory=visual_scans_folder+task_file\n",
        "  temp=substring_after(file_directory,\"run\")\n",
        "  run_index=temp[0]\n",
        "  print(\"Now reading run number %s of the visual test.\" %(run_index))\n",
        "  current_run=sio.loadmat(file_directory)\n",
        "  experiment_start_time=current_run['ExpStartTimeP']\n",
        "  trial_start=current_run['stimulusStartTimeP']-experiment_start_time ##This is also grip start time\n",
        "  grip_end_time=current_run['relaxStartTimeP']-experiment_start_time\n",
        "  first_stimulus_start=current_run['SoundStartTimeP']-experiment_start_time\n",
        "  first_stimulus_end=current_run['g1_OffsetTimeP']-experiment_start_time\n",
        "  second_stimulus_end=current_run['g2_OffsetTimeP']-experiment_start_time\n",
        "  second_stimulus_start=current_run['g2_OnsetTimeP']-experiment_start_time\n",
        "  grip_length=grip_end_time-trial_start\n",
        "  first_stimulus_length=first_stimulus_end-first_stimulus_start\n",
        "  second_stimulus_length=second_stimulus_end-second_stimulus_start\n",
        "  visual_first_vector=np.zeros(2*np.shape(first_stimulus_start)[1])\n",
        "  visual_second_vector=np.zeros(2*np.shape(first_stimulus_start)[1])\n",
        "  grip_first_vector=np.zeros(np.shape(trial_start)[1])\n",
        "  grip_second_vector=np.zeros(np.shape(trial_start)[1])\n",
        "  j=0\n",
        "  for i in range(np.shape(first_stimulus_start)[1]):\n",
        "    grip_first_vector[i]=trial_start[0,i]\n",
        "    grip_second_vector[i]=grip_length[0,i]\n",
        "    if j%2 ==0:\n",
        "      visual_first_vector[j]=first_stimulus_start[0,i]\n",
        "      visual_second_vector[j]=first_stimulus_length[0,i]\n",
        "      j=j+1\n",
        "    if j%2 !=0:\n",
        "      visual_first_vector[j]=second_stimulus_start[0,i]\n",
        "      visual_second_vector[j]=second_stimulus_length[0,i]\n",
        "      j=j+1\n",
        "  visual_ev=np.column_stack((visual_first_vector,visual_second_vector,visual_ones)) \n",
        "  grip_ev=np.column_stack((grip_first_vector,grip_second_vector,grip_ones)) \n",
        "  visual_filename=f\"visual_run_{run_index}.txt\"\n",
        "  ev1_adress=save_dir_vis+visual_filename\n",
        "  grip_filename=f\"visual_grip_run_{run_index}.txt\"\n",
        "  ev2_adress=save_dir_vis+grip_filename\n",
        "  fmt = ['%.4f', '%.4f', '%d']\n",
        "  np.savetxt(ev1_adress,visual_ev, delimiter=\" \",fmt=fmt)\n",
        "  np.savetxt(ev2_adress,grip_ev, delimiter=\" \",fmt=fmt)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6rpvpew3xBq",
        "outputId": "555e039d-63f3-445d-da43-558f421216c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now reading run number 1 of the visual test.\n",
            "Now reading run number 2 of the visual test.\n",
            "Now reading run number 3 of the visual test.\n",
            "Now reading run number 4 of the visual test.\n",
            "Now reading run number 5 of the visual test.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ev_file_adress=save_dir_vis+grip_filename\n",
        "ev_file_adress"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tbdmdeS5-19B",
        "outputId": "ac004f57-64df-4b86-e16a-5d10754d660d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/Shareddrives/LC-Aging/LC_aging_fMRI/BAP102/visual_grip_run_5.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Because in some of the subjects the number of auditory tasks might differ from the visual ones\n",
        "## we need to exploit 2 for loops, one for each here.\n",
        "## This section is only for the auditory test\n",
        "number_of_trials_per_run=30\n",
        "audio_ones=np.ones(2*number_of_trials_per_run)\n",
        "grip_ones=np.ones(number_of_trials_per_run)\n",
        "for current_file in audio_files:\n",
        "  task_file=current_file\n",
        "  file_directory=audio_scans_folder+task_file\n",
        "  temp=substring_after(file_directory,\"run\")\n",
        "  run_index=temp[0]\n",
        "  print(\"Now reading run number %s of the auditory test.\" %(run_index))\n",
        "  current_run=sio.loadmat(file_directory)\n",
        "  experiment_start_time=current_run['ExpStartTimeP']\n",
        "  trial_start=current_run['stimulusStartTimeP']-experiment_start_time ##This is also grip start time\n",
        "  grip_end_time=current_run['relaxStartTimeP']-experiment_start_time\n",
        "  first_stimulus_start=current_run['SoundStartTimeP']-experiment_start_time\n",
        "  first_stimulus_end=first_stimulus_start+0.1 ## Seems like we don't have the exact timings\n",
        "  second_stimulus_start=first_stimulus_end+0.5\n",
        "  second_stimulus_end=second_stimulus_start+0.1\n",
        "\n",
        "  grip_length=grip_end_time-trial_start\n",
        "  first_stimulus_length=first_stimulus_end-first_stimulus_start\n",
        "  second_stimulus_length=second_stimulus_end-second_stimulus_start\n",
        "  audio_first_vector=np.zeros(2*np.shape(first_stimulus_start)[1])\n",
        "  audio_second_vector=np.zeros(2*np.shape(first_stimulus_start)[1])\n",
        "  grip_first_vector=np.zeros(np.shape(trial_start)[1])\n",
        "  grip_second_vector=np.zeros(np.shape(trial_start)[1])\n",
        "  j=0\n",
        "  for i in range(np.shape(first_stimulus_start)[1]):\n",
        "    grip_first_vector[i]=trial_start[0,i]\n",
        "    grip_second_vector[i]=grip_length[0,i]\n",
        "    if j%2 ==0:\n",
        "      audio_first_vector[j]=first_stimulus_start[0,i]\n",
        "      audio_second_vector[j]=first_stimulus_length[0,i]\n",
        "      j=j+1\n",
        "    if j%2 !=0:\n",
        "      audio_first_vector[j]=second_stimulus_start[0,i]\n",
        "      audio_second_vector[j]=second_stimulus_length[0,i]\n",
        "      j=j+1\n",
        "  audio_ev=np.column_stack((audio_first_vector,audio_second_vector,audio_ones)) \n",
        "  grip_ev=np.column_stack((grip_first_vector,grip_second_vector,grip_ones)) \n",
        "  audio_filename=f\"audio_run_{run_index}.txt\"\n",
        "  ev1_adress=save_dir_aud+audio_filename\n",
        "  grip_filename=f\"audio_grip_run_{run_index}.txt\"\n",
        "  ev2_adress=save_dir_aud+grip_filename\n",
        "  fmt = ['%.4f', '%.4f', '%d']\n",
        "  np.savetxt(ev1_adress,audio_ev, delimiter=\" \",fmt=fmt)\n",
        "  np.savetxt(ev2_adress,grip_ev, delimiter=\" \",fmt=fmt)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHlalmJzYxq1",
        "outputId": "fe72d9ef-9a4c-4ca4-a4e5-c04fcfa76fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now reading run number 1 of the auditory test.\n",
            "Now reading run number 2 of the auditory test.\n",
            "Now reading run number 3 of the auditory test.\n",
            "Now reading run number 4 of the auditory test.\n",
            "Now reading run number 5 of the auditory test.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_stimulus_start"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvMeOTdkicNN",
        "outputId": "35903cb9-228e-4c0b-d061-b62049647a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  3.8099293,  16.0206326,  29.8313092,  42.2615242,  56.2621671,\n",
              "         72.0135609,  87.7638165, 103.5049449, 119.2555947, 133.2561306,\n",
              "        145.5063155, 159.5073296, 173.5076996, 185.758313 , 198.0091031,\n",
              "        210.2594204, 224.2603517, 240.0115014, 252.2615588, 264.5121072,\n",
              "        280.2530545, 294.2535608, 308.2540974, 322.2545207, 336.2554879,\n",
              "        348.5062499, 362.5065597, 374.7572263, 387.0081127, 401.0084801]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visual_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxRMQw8dS3R8",
        "outputId": "55bfc3c6-1aa4-42ba-ad00-ed840864f4f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['subjectBAP103_Voddball_session2_run1_7_6_13_15.mat',\n",
              " 'subjectBAP103_Voddball_session2_run2_7_6_13_25.mat',\n",
              " 'subjectBAP103_Voddball_session2_run3_7_6_13_34.mat',\n",
              " 'subjectBAP103_Voddball_session2_run4_7_6_13_42.mat',\n",
              " 'subjectBAP103_Voddball_session2_run5_7_6_13_51.mat']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "z=os.listdir(base_dir)\n",
        "type(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QObxRO7vuL2P",
        "outputId": "70ee65cc-577c-49e2-8f21-c069fc97db61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "54p6aKfiuQLF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}